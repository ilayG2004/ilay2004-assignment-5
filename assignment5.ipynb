{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQTNx6uaxEuF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AA3PlmQOxEuI"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Store training data for later use in rest of class\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_predicted = []\n",
        "        for test_point in X:\n",
        "          distances = self.compute_distance(test_point, self.X_train)\n",
        "\n",
        "          k_nn_indicies = np.argsort(distances)[:self.k]\n",
        "          k_nn_labels = [self.y_train[i] for i in k_nn_indicies] #Go into the training data, and grab the class of each of the k-nearest points\n",
        "\n",
        "          #Which classification is most common\n",
        "          dic = {}\n",
        "          for label in k_nn_labels:\n",
        "            if label in dic:\n",
        "              dic[label] += 1\n",
        "            else:\n",
        "              dic[label] = 1\n",
        "\n",
        "          #Probability of exited = votes for exiting (1)/total votes (k)\n",
        "          pr_exit = dic.get(1,0)/self.k\n",
        "          y_predicted.append(pr_exit)\n",
        "        return np.array(y_predicted)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.linalg.norm(X2 - X1, axis=1)\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.abs(X2 - X1).sum(axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EbsYfJfzxEuI"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    #Remove irrelevant data & separate the result from the attributes we're looking at\n",
        "    X = train_data.drop(['Exited', 'id', 'CustomerId', 'Surname'], axis=1)\n",
        "    y = train_data['Exited']\n",
        "\n",
        "    #Numerical values vs. Categorical values. Used to determine which is more important later\n",
        "    num_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    cat_features = ['Geography', 'Gender']\n",
        "\n",
        "    #Process numerical values by mean, & categorical values by frquencies\n",
        "    preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('num', Pipeline(steps=[\n",
        "              ('imputer', SimpleImputer(strategy='mean')),\n",
        "              ('scaler', StandardScaler())\n",
        "          ]), num_features),\n",
        "          ('cat', Pipeline(steps=[\n",
        "              ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "              ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "          ]), cat_features)\n",
        "      ])\n",
        "\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    X_test = test_data.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "    return X_processed, y, X_test_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jHNLyVGFxEuJ"
      },
      "outputs": [],
      "source": [
        "#Scikit learn cv_scoring has been problematic using my custom knn class so cross validation will be done manually\n",
        "def roc_auc_score_manual(y_true, y_pred):\n",
        "    #Define exited (1) or not exited (0)\n",
        "    pos_label = 1\n",
        "    neg_label = 0\n",
        "\n",
        "    # Sorting by predicted scores\n",
        "    desc_sort_order = np.argsort(-y_pred)\n",
        "    y_true_sorted = y_true.iloc[desc_sort_order]\n",
        "\n",
        "    #Compare true positives & false positives\n",
        "    true_positives = np.cumsum(y_true_sorted == pos_label) / np.sum(y_true == pos_label)\n",
        "    false_positives = np.cumsum(y_true_sorted == neg_label) / np.sum(y_true == neg_label)\n",
        "\n",
        "    #Area under the curve using the trapezoidal rule\n",
        "    auc = np.trapz(true_positives, false_positives)\n",
        "\n",
        "    return auc\n",
        "\n",
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    n = len(y)\n",
        "    indicies = np.arange(n)\n",
        "    np.random.shuffle(indicies)\n",
        "    fold_sizes = np.full(n_splits, n // n_splits, dtype=int)\n",
        "    fold_sizes[:n % n_splits] += 1\n",
        "\n",
        "    current = 0\n",
        "    scores = []\n",
        "\n",
        "    for fold_size in fold_sizes:\n",
        "        val_indicies = indicies[current:current + fold_size]\n",
        "        train_indicies = np.setdiff1d(indicies, val_indicies)\n",
        "\n",
        "        X_train, X_val = X[train_indicies], X[val_indicies]\n",
        "        y_train, y_val = y.iloc[train_indicies], y.iloc[val_indicies]\n",
        "\n",
        "        knn.fit(X_train, y_train.to_numpy())\n",
        "        y_pred = knn.predict(X_val)\n",
        "\n",
        "        #Find roc auc score by comparing the data we found from the actual\n",
        "        score = roc_auc_score_manual(y_val, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "        current += fold_size\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erL2SSX4xEuK",
        "outputId": "97cfc0c4-850d-436b-c387-4a97711d8e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.8633854787967192, 0.880079245471765, 0.8780488131965544, 0.8694667078818714, 0.8737142773705169]\n",
            "Mean cross-validation score: 0.8729389045434853\n",
            "5 euclidean [0.8839734668223039, 0.8695079967470858, 0.8688471832758936, 0.8718126746509043, 0.8734194298883522]\n",
            "5 euclidean 0.8735121502769079\n",
            "5 manhattan [0.860120144417136, 0.8744483646094322, 0.8603962856074114, 0.8872720336174704, 0.869598475383918]\n",
            "5 manhattan 0.8703670607270737\n",
            "7 euclidean [0.8882950691142132, 0.8816058626775909, 0.884873159107039, 0.8722394368592942, 0.8997920997920998]\n",
            "7 euclidean 0.8853611255100473\n",
            "7 manhattan [0.8789226867268242, 0.8864121263157896, 0.8963763448685346, 0.8819200580606263, 0.8786869059144516]\n",
            "7 manhattan 0.8844636243772455\n",
            "9 euclidean [0.9065242317483162, 0.9001359490895933, 0.8840064074468897, 0.8807698857608683, 0.8978093532265249]\n",
            "9 euclidean 0.8938491654544386\n",
            "9 manhattan [0.8795399601175101, 0.8926210331531794, 0.9026229712224916, 0.8940373844918181, 0.8861542209975644]\n",
            "9 manhattan 0.8909951139965127\n",
            "11 euclidean [0.8959693259470967, 0.9009318606514989, 0.8991696975567944, 0.9078379164819025, 0.8840481470689805]\n",
            "11 euclidean 0.8975913895412546\n",
            "11 manhattan [0.9006057430861423, 0.9017322707308215, 0.8811132643428152, 0.8830099311708602, 0.8976293357132002]\n",
            "11 manhattan 0.892818109008768\n",
            "13 euclidean [0.9025684210526317, 0.9038804258759962, 0.9008165634115428, 0.8983387396455123, 0.8955688369125154]\n",
            "13 euclidean 0.9002345973796396\n",
            "13 manhattan [0.8904830365580773, 0.8970013170028586, 0.8934228511417304, 0.9104400859738221, 0.9022261937765623]\n",
            "13 manhattan 0.8987146968906101\n",
            "20 euclidean [0.9010708333333335, 0.9070877912198503, 0.9077534385860998, 0.9114191526503486, 0.9040741533428984]\n",
            "20 euclidean 0.906281073826506\n",
            "20 manhattan [0.8979624786076399, 0.8996409496053706, 0.9026249462516802, 0.9055979987512359, 0.9005863250708795]\n",
            "20 manhattan 0.901282539657361\n",
            "20 euclidean\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "mean = np.mean(cv_scores)\n",
        "print(\"Mean cross-validation score:\", mean)\n",
        "\n",
        "# TODO: hyperparamters tuning. Figure out the optimal k value or distance metric\n",
        "opt_k = 0\n",
        "opt_distance_metric = 0\n",
        "best_score = -np.inf\n",
        "\n",
        "#Loop through different values of k and metrics. Essentially reapply the steps from above, but this time we are repeating these steps until we find the best score\n",
        "for k in [5, 7, 9, 11, 13, 20]:\n",
        "    for metric in ['euclidean', 'manhattan']:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        cv_score = cross_validate(X,y,knn)\n",
        "        mean_score = np.mean(cv_score)\n",
        "        print(k, metric, cv_score)\n",
        "        print(k, metric, mean_score)\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            opt_k = k\n",
        "            opt_distance_metric = metric\n",
        "\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "print(opt_k, opt_distance_metric)\n",
        "knn = KNN(k=opt_k, distance_metric= opt_distance_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
